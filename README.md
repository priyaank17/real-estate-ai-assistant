# Silver Land Properties AI Assistant

Production-grade real estate AI agent with local LLM (Ollama), MCP tools, and hybrid search.

## ğŸ“ Project Structure

```
real-estate-ai-assistant/
â”œâ”€â”€ agents/                    # Django app (web layer only)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ models.py             # Django models (Project, Lead, Booking)
â”‚   â”œâ”€â”€ api.py                # REST API endpoints (uses MCP client)
â”‚   â”œâ”€â”€ graph.py              # LangGraph agent definition
â”‚   â”œâ”€â”€ apps.py
â”‚   â”œâ”€â”€ admin.py
â”‚   â””â”€â”€ migrations/
â”‚
â”œâ”€â”€ tools/                     # Business logic tools (LangChain tools)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ sql_tool.py           # Text-to-SQL (uses helpers.vanna)
â”‚   â”œâ”€â”€ rag_tool.py           # Semantic search (uses helpers.vectorstore)
â”‚   â”œâ”€â”€ booking_tool.py       # Property viewing bookings
â”‚   â”œâ”€â”€ investment_tool.py    # ROI/yield calculations
â”‚   â”œâ”€â”€ comparison_tool.py    # Side-by-side comparisons
â”‚   â”œâ”€â”€ ui_tool.py            # UI context updates
â”‚   â””â”€â”€ web_tool.py           # Web search
â”‚
â”œâ”€â”€ helpers/                   # Utilities, clients, adapters
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ vanna.py              # Vanna client singleton
â”‚   â””â”€â”€ vectorstore.py        # ChromaDB vectorstore + embeddings
â”‚
â”œâ”€â”€ mcp/                       # MCP server (separate service)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ server.py             # FastMCP server (exposes tools)
â”‚
â”œâ”€â”€ scripts/                   # Setup & maintenance
â”‚   â”œâ”€â”€ vanna_setup.py        # Train Vanna (one-time)
â”‚   â”œâ”€â”€ ingest_rag.py         # Ingest RAG data (one-time)
â”‚   â””â”€â”€ seed_database.py      # Seed DB from CSV
â”‚
â”œâ”€â”€ data/                      # Data files
â”‚   â””â”€â”€ properties.csv        # 17k+ property listings
â”‚
â”œâ”€â”€ tests/                     # Test suite
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_tools.py         # Unit tests
â”‚   â””â”€â”€ test_api.py           # Integration tests
â”‚
â”œâ”€â”€ silver_land/               # Django settings
â”‚   â”œâ”€â”€ settings.py
â”‚   â”œâ”€â”€ urls.py
â”‚   â”œâ”€â”€ wsgi.py
â”‚   â””â”€â”€ asgi.py
â”‚
â”œâ”€â”€ chroma_rag/               # RAG vector DB (gitignored)
â”œâ”€â”€ chroma_vanna/             # Vanna index (gitignored)
â”œâ”€â”€ db.sqlite3                # SQLite database (gitignored)
â”œâ”€â”€ manage.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## ğŸ¯ Architecture Highlights

### Clean Separation of Concerns

| Layer | Directory | Purpose | Examples |
|-------|-----------|---------|----------|
| **Web** | `agents/` | Django app, API, ORM models | api.py, models.py, graph.py |
| **Business Logic** | `tools/` | LangChain tools (@tool decorator) | sql_tool.py, rag_tool.py |
| **Helpers** | `helpers/` | Clients, adapters, utilities | vanna.py, vectorstore.py |
| **MCP Service** | `mcp/` | Tool exposure via MCP | server.py |
| **Scripts** | `scripts/` | CLI utilities, setup | seed_database.py |

### Why Helpers?

**Before:**
```python
# tools/rag_tool.py (mixed)
def get_vectorstore():  # â† Helper function
    ...

@tool
def search_rag():  # â† Actual tool
    ...
```

**After:**
```python
# helpers/vectorstore.py (pure helper)
def get_vectorstore():
    ...

# tools/rag_tool.py (pure tool)
from helpers.vectorstore import get_vectorstore

@tool
def search_rag():
    vectorstore = get_vectorstore()
    ...
```

**Benefits:**
- âœ… Tools are pure business logic
- âœ… Helpers are reusable across multiple tools
- âœ… Easy to mock helpers in tests
- âœ… Follows Single Responsibility Principle

## ğŸš€ Quick Start

### 1. Prerequisites
- Python 3.12+
- Ollama installed ([download](https://ollama.ai/download))

### 2. Install & Setup
```bash
# Clone repo
cd real-estate-ai-assistant

# Create virtual environment
python3 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Pull Ollama models
ollama pull llama3.1         # ~4.7GB
ollama pull nomic-embed-text # ~274MB
```

### 3. Initialize Database
```bash
# Run migrations
python manage.py migrate

# Seed from CSV (17k+ properties)
python scripts/seed_database.py
```

### 4. Train AI Components
```bash
# Train Vanna (Text-to-SQL)
python scripts/vanna_setup.py

# Ingest RAG data
python scripts/ingest_rag.py
```

### 5. Run Application
```bash
# Start Django server (automatically connects to MCP)
python manage.py runserver 8000
```

## ğŸ”§ Architecture

### MCP Client Pattern
```
API â†’ MultiServerMCPClient â†’ MCP Server â†’ Tools â†’ Helpers
```

**Data Flow:**
1. User sends request to **REST API** (`agents/api.py`)
2. API uses **MCP Client** to connect to MCP server
3. **MCP Server** (`mcp/server.py`) exposes tools
4. **Tools** (`tools/`) contain business logic
5. **Helpers** (`helpers/`) provide shared utilities
6. Results flow back to user

## ğŸ“¡ API Usage

### Chat Endpoint
**POST** `/api/agents/chat`

```json
{
  "message": "Find 2 bedroom apartments in Dubai under 500k"
}
```

**Response:**
```json
{
  "response": "I found 3 apartments...",
  "conversation_id": "<uuid>",
  "data": {
    "shortlisted_project_ids": [101, 102, 103]
  }
}
```

## ğŸ§ª Testing

```bash
# Run all tests
python manage.py test tests

# Run specific tests
python manage.py test tests.test_tools
```

## ğŸ› ï¸ Development

### Adding a New Tool

1. **Create tool** in `tools/new_tool.py`:
```python
from langchain_core.tools import tool
from helpers.vanna import get_vanna_client  # Use helpers

@tool
def my_new_tool(query: str) -> str:
    """Tool description."""
    vn = get_vanna_client()
    return vn.query(query)
```

2. **Expose** in `mcp/server.py`:
```python
from tools.new_tool import my_new_tool

@mcp.tool()
def my_new_tool_mcp(query: str) -> str:
    return my_new_tool.invoke(query)
```

3. **Restart** server

### Adding a New Helper

1. Create file in `helpers/my_helper.py`
2. Import in tools: `from helpers.my_helper import ...`
3. Use across multiple tools

## ğŸ¯ Performance

### Ollama vs OpenAI

| Metric | Ollama (Local) | OpenAI (Cloud) |
|--------|----------------|----------------|
| Cost | $0 (Free) | ~$0.03/request |
| Privacy | 100% Local | Data sent to API |
| Speed | Slower | Faster |
| Internet | Not required | Required |

### Recommended Hardware
- **Minimum**: 8GB RAM, 4-core CPU
- **Recommended**: 16GB RAM, 8-core CPU
- **Storage**: ~10GB for models + data

---

**Built with LangGraph, Django Ninja, Ollama, and MCP**
